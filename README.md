---
tags:
  - 2-1/자료구조
draft: true
---
## 1. 계획(Planning)
- **개요**
	- 2학년 1학기 자료구조 개인 과제
	- Word Frequency Counter 프로그램 개발

- **개발 환경**
	- C
	- Ubuntu Linux
	- Vim

## 2. 요구사항 분석(Requirement Analysis)
- 먼저 프로그램이 '무엇을 해야 하는지'를 잘 정리해야 나중에 개발이 쉬워진다.

### 2.1. 기능적 요구사항(Functional Requirement)
|  FR   |                                                                    내용                                                                    |
| :---: | :--------------------------------------------------------------------------------------------------------------------------------------: |
| 인자 처리 |      인자 개수가 2개가 아니면<br>↳ 사용법 메시지를 출력하고 종료(`exit code 1`)<br>search_freq가 정수로 ==파싱==되지 않거나 ≤0 이면<br>↳ 에러 메시지를 출력하고 종료(`exit code 2`)      |
| 파일 열기 |                                           하드코딩된 경로(`../words/tom-word-list.txt`)에서 텍스트를 읽어온다.                                            |
| 빈도 누적 |                                                    공백 기준으로 ==토큰화==하여 단어별 출현 횟수를 집계한다.                                                    |
| P1 출력 |                                                       전체 단어 수(합계)와 고유 단어 수를 출력한다.                                                        |
| P2 출력 |   단어(키) 기준 오름차순 정렬된 리스트에서:<br>↳ 상위 10개 단어·빈도 출력, 하위 10개 단어·빈도 출력<br>사용자 지정 search_word가 존재하면 해당 단어와 빈도 출력<br>↳ 없으면 “탐색지정단어(%s) 없음” 메시지   |
| P3 출력 | (빈도, 단어) 쌍을 빈도 기준 내림차순 정렬하여:<br>↳ 상위 10개 빈도·단어 출력, 하위 10개 빈도·단어 출력<br>사용자 지정 search_freq 값과 동일한 빈도를 가진 모든 단어 출력<br>↳ 없으면 “ 해당 단어 없음” 메시지 |
- 과제에서 제시된 프로그램의 기능적 요구사항은 텍스트를 토큰화해서 고유 단어 수와 출현 빈도 수를 집계 및 탐색하는 정도로 볼 수 있다.

#### (1) 파싱, 토큰화화
- **파싱**(parsing)
	- 컴퓨터 과학에서 문자열을 구조적으로 분석하는 과정을 의미
	- 정해진 문법이나 규칙에 따라 나누고, 그 의미를 해석하는 작업
	- 제공된 프로그램에서는 명령행 인자의 수를 정수로 파싱하는 정도만 진행된다.

- **토큰화**(tokenization)
	- 텍스트 처리에서 문장을 의미 있는 단위(토큰)로 나누는 작업
	- 주로 자연어 처리(NLP)에서 중요한 전처리 단계로 사용
	- 제공된 프로그램에서는 영어 문법에서 공백 기준으로 토큰화를 하기 때문에, 단어 수준 토큰화 작업이 실행된다.

### 2.2. 비기능적 요구사항(Non-functional requirement)
|  NFR  |                                               내용                                                |
| :---: | :---------------------------------------------------------------------------------------------: |
| 실행 환경 |                             ==Ubuntu Linux 서버에서 컴파일 및 실행== 가능해야 한다.                             |
|  성능   | 프로그램 실행 후 1분 이내에 모든 처리가 완료되어야 한다.<br>최소 $O(n\log{n})$ 알고리즘(퀵, 병합, 힙, 트리 정렬 등)을 사용해 적절한 처리 속도 보장 |
|  현지화  |                               모든 화면 출력(메시지, 라벨 등)은 한글로 표시되어야 한다.                                |
| 유지보수성 |                         ==Makefile==을 통해 make로 빌드하고 make clean으로 일괄 삭제                          |
|  가용성  |                       명령행 인자(탐색지정단어, 탐색지정빈도)를 통해 가변적으로 기능을 제어할 수 있어야 한다.                        |
|  안정성  |      잘못된 입력(인수 개수, 빈도 값 오류 등)에 대해 명확한 한글 오류 메시지를 출력하고,<br>지정된 종료 코드(1 또는 2)로 안전하게 종료해야 한다.      |

### 2.3. 유스 케이스(Use Case)
|         UC         |                    설명                    |
| :----------------: | :--------------------------------------: |
|  잘못된 ==인자 개수 처리==  |       인자가 2개가 아니면 사용법 메시지 출력 후 종료        |
| 단어 카운팅 및 요약 ==출력== |    파일에서 단어 카운팅 후 P1, P2, P3 섹션별 결과 출력    |
|     단어 ==탐색==      |  지정 단어의 빈도를 찾아 출력, 없으면 “탐색지정단어(%s) 없음”   |
|     빈도 ==탐색==      | 지정 빈도에 해당하는 단어 전부 찾아 출력, 없으면 “ 해당 단어 없음” |
- 사용자와 어떻게 상호작용하는지
- 테스트 케이스를 만들거나 오류를 처리할 때도 `이 요구사항을 만족시키는가?`라는 기준 형성

## 3. 설계(Design)
![](https://imgur.com/JASJQ2E.png)
- 분석한 요구사항에 따라, 크게 인자 처리 -> 단어 집계 -> 정렬 및 탐색으로 구성
- 인자를 입력받아 처리하고, 검증에 성공하면 단어를 집계한 뒤 빈도를 누적시켜 전체 결과를 출력한다.
- 정렬 및 탐색은 크게 사전 순 정렬과 사전 값 탐색, 빈도 순 정렬과 빈도 순 탐색을 하게된 뒤 프로그램이 종료하게 된다.

### 3.1. 인자 처리
|  설계  |                                           내용                                            |
| :--: | :-------------------------------------------------------------------------------------: |
|  역할  | 사용자로부터 search_word(탐색할 단어), search_freq(탐색할 빈도)를 명령행 인자를 받음<br>제공된 프로그램과 동일한 유효성 검증을 수행 |
| 요소 1 |                                  argc/argv 검사 (인자 개수)                                   |
| 요소 2 |                  빈도는 음수가 될 수 없으므로, atoi()로 search_freq를 정수로 파싱 및 양수 검사                  |
| 요소 3 |                              에러 시 한글 메시지 출력 후 지정 종료 코드 반환                               |
- 인자 처리는 인자 개수에 대한 검사와 올바른 범위 내의 정수 빈도 파싱으로 설계

### 3.2. 단어 집계
|   설계   |                                                        내용                                                        |
| :----: | :--------------------------------------------------------------------------------------------------------------: |
|   역할   |                                   텍스트 파일(tom-word-list.txt)을 읽어 모든 단어를 빠르게 집계                                    |
| 파일 I/O |                                       fopen() 후 텍스트 파일에서 공백 단위로 읽어 단어를 추출                                        |
| 해시 테이블 | 데이터를 키(key)와 값(value)의 쌍으로 저장하는 자료구조<br>word 키, count 값 쌍으로 저장<br>직관적인 키 접근 기반, 매우 빠른 검색 속도(O(1)), 해시 함수의 성능에 의존 |
| 집계 통계  |                 전체 단어 수(total_words) 누적: (→ 74388 단어)<br>고유 단어 수(HASH_COUNT(table)): (→ 8043 단어)                 |

#### (1) 해시 테이블
- 자료구조를 배웠으면 프로그램에 맞는, order of가 제일 낮은 자료구조 사용하자!
	- 해시 테이블 자료구조에 집계 결과를 저장하기로 설계 (단어 키와 빈도 값을 쌍으로 저장)

- 하지만 C는 해시 테이블 자료형이 없다!
	- C는 저수준 언어라서 해시 테이블을 직접 만들거나
	- 이미 구현된 해시 테이블 라이브러리를 활용하면 된다!

#### (2) uthash
- `uthash`: 널리 쓰이는 해시 테이블 라이브러리
	- 오픈소스로 헤더 파일만 다운 받으면 된다.
	- 매우 가볍고 간단하게 구조체에 핸들만 붙이면 매크로 사용 가능
	- Troy D. Hanson의 uthash: troydhanson.github.io/uthash

|    역할    |                                                                   사용법                                                                    |
| :------: | :--------------------------------------------------------------------------------------------------------------------------------------: |
|  핸들 정의   |                                                           `UT_hash_handle hh;`                                                           |
|    탐색    |             `HASH_FIND_STR(table, token, e);`<br>table에서 문자열 키 token과 같은 엔트리가 있는지 찾음<br>찾으면 e에 해당 구조체 포인터를 리턴, 못 찾으면 NULL 리턴             |
|    삽입    | `HASH_ADD_KEYPTR(hh, table, e->word, strlen(e->word), e);`<br>새로 할당한 구조체 e를 table 에 추가<br>핸들, 테이블, 키, 키 길이, 삽입할 구조체를 순서대로 인자에 전달하여 사용한다. |
| 전체 개수 조회 |                                   `unique_words = HASH_COUNT(table);`<br>해시 테이블에 등록된 총 엔트리(고유 키) 수를 반환                                   |
|  반복 순회   |           `HASH_ITER(hh, table, cur, tmp) { ... }`<br>해시 테이블의 모든 엔트리를 순회(iterate)<br>핸들, 테이블, 반복자, 임시 포인터를 순서대로 인자에 전달하여 사용한다.           |
- 해시 함수 매크로는 4가지만 사용했습니다. 차례대로 탐색과 삽입, 전체 개수 조회, 반복 순회입니다.

### 3.3. 정렬 및 탐색
|         설계         |                                             내용                                              |
| :----------------: | :-----------------------------------------------------------------------------------------: |
|         역할         |                         요구사항에 맞춰 두 가지 기준으로 정렬<br>검색할 단어/검색할 빈도에 대응                          |
| 단어 기준  <br>오름차순 정렬 |      `qsort(..., cmp_word_asc)`<br>상위/하위 10개 단어·빈도 선택<br>HASH_FIND_STR로 search_word 조회      |
| 빈도 기준  <br>내림차순 정렬 | `qsort(..., cmp_freq_desc)`<br>상위/하위 10개 빈도·단어 선택<br>배열 전체 순회하며 count == search_freq인 항목 출력 |
- 정렬은 퀵소트 내장함수와 직접 작성한 기준 함수를 사용
- 탐색은 키값 검색 매크로와 순회 매크로를 사용

## 4. 구현(Implementation)
### 4.1. 구조체와 정렬 기준→퀵 정렬
```c
// 구조체
typedef struct {
	char *word;			// 키: 단어 문자열
	int count;			// 값: 출현 빈도
	UT_hash_handle hh;	// uthash 내부 해시 테이블 핸들
} WordEntry;

// 정렬 기준 함수:  <일 때 음수, =일 때 0, >일 때 양수 리턴
int cmp_word_asc() {...}		// 정렬 기준 1: 단어 기준*  
return strcmp(ea->word, eb->word);
int cmp_freq_desc() {...}		// 정렬 기준 2: 빈도 기준*
return eb->count - ea->count;	// (추가로 빈도 동점 시 정렬 기준 1 사용)

// 퀵 정렬: stdlib.h에서 기본으로 제공하는 퀵 정렬 함수 qsort  
// 배열 시작 주소, 요소 수, 요소 크기, 함수 포인터를 순서대로 인자에 전달하여 사용
qsort(arr, unique_words, sizeof(*arr), cmp_word_asc); // 매크로 → unique_words
qsort(arr, unique_words, sizeof(*arr), cmp_freq_desc);
```

### 4.2. 인자 처리 및 단어 집계
```c
// FR1 인자 처리
if (argc != 3) return 1;			// 인자 개수 확인 후 사용법 출력
int search_freq = atoi(argv[2]);	// 아스키 투 인티저로 정수 파싱 후
if (search_freq <= 0) return 2;		// ↳ 탐색지정빈도 입력 오류 출력

// FR2 파일 열기
FILE *fp = fopen(FILE_PATH, "r");

// FR3 빈도 누적
total_words++; // 전체 단어 수 누적

HASH_FIND_STR(table, token, e); // 이미 존재하는 단어인지 해시에서 찾기
if (e) e->count++; // 있으면 빈도 누적
HASH_ADD_KEYPTR(hh, table, e->word, strlen(e->word), e); // 없으면 삽입

fclose(fp); // 파일 닫기
unique_words = HASH_COUNT(table); // 고유 단어 수
```

### 4.3. 정렬 및 탐색
```c
// P2 단어 정렬
qsort(arr, unique_words, sizeof(*arr), cmp_word_asc);

// P2 상단 출력
for (idx = 0; idx < limit; ++idx) // 고유 단어 수가 10 이상이면 limit = 10

// P2 하단 출력
for (idx = unique_words - limit; idx < unique_words; ++idx)
// idx = unique_words - limit 끝의 10 앞에서
// idx < unique_words 끝이 될 때 까지
// ++idx 하나씩

// P2 단어 탐색
HASH_FIND_STR(table, search_word, found_word); // 단어가 키 값이므로 매크로로 찾는다.

// P3 빈도 정렬
qsort(arr, unique_words, sizeof(*arr), cmp_freq_desc);

// P3 상단 출력 (P2의 상단 출력과 같음)
// P3 하단 출력 (P2의 하단 출력과 같음)

// P3 빈도 탐색
if (arr[idx]->count == search_freq) { ... } // 탐색할 빈도와 같은 빈도만 모두 출력한다.
```

## 5. 테스트(Testing)
|       UC        |                                                                                             설명                                                                                              |
| :-------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
|  잘못된 인자 개수 처리   |                                                                                 인자가 2개가 아니면 사용법 메시지 출력 후 종료                                                                                 |
| 단어 카운팅 및 요약 출력  |                                                                파일에서 단어 카운팅 후 P1, P2, P3 섹션별 결과 출력<br>전체 74388 단어, 고유 8043 단어                                                                |
|      단어 검색      |                                             지정 단어의 빈도를 찾아 출력, 없으면 “탐색지정단어(%s) 없음”<br>과제 설명서 예시 1: ('beautiful', 8)<br>과제 설명서 예시 2: ('Tom', 806)                                             |
|      빈도 검색      | 지정 빈도에 해당하는 단어 전부 찾아 출력, 없으면 “ 해당 단어 없음”<br>과제 설명서 예시 1: (33, 'lost'), (33, 'mean'), (33, 'sleep'), (33, 'try')<br>과제 설명서 예시 2: (55, 'Potter'), (55, 'another'), (55, 'make'), (55, 'till') |
| + 성능 (time 명령어) |                                                                    과제 설명서 예시: real 0m0.035s, user 0m0.033s, sys 0m0.003s                                                                    |
- 테스트 기준은 처음에 유스 케이스를 기준으로 삼았습니다.
- 비교 및 검증 대상은 과제 설명서로 제공된 예시들을 모두 참고하였습니다.

### 5.1. Exception Handling
![](https://imgur.com/nxuQjfE.png)
- 잘못된 인자에 대한 예외 처리
	- 잘못된 개수의 인자
	- 정수로 파싱할 수 없는 빈도값
	- 논리적으로 불가능한 빈도값

- 프로그램이 동작하는 대신 사용법 안내 또는 오류 안내

### 5.2. `time ./wordCount beautiful 33`
![|400](https://imgur.com/O5b6X5A.png)
![|400](https://imgur.com/b6IeI5U.png)

### 5.3. `time ./wordCount Tom 55`
![|400](https://imgur.com/b6pcleZ.png)
![|400](https://imgur.com/BrlPA2i.png)

## 6. 회고
- **요구사항 분석**
	- 내가 사용했던 이유: 간단하고 쉬운 프로그램이 아니라면 제대로 된 요구사항이 필요한 것을 느껴서 사용했다.
	- 교수님 관점 평가
		- 개발 전에 미리 완벽한 길을 찾는 방법
		- 요구사항 분석이 완벽할 수록 뒤따르는 시행 착오, 오류, 예외 처리 등을 작업할 필요가 없어진다.
	- 후기: 설계, 구현, 테스트까지 분석의 내용을 연결 가능한 것이 좋은 점 같다.

- **오픈 소스 활용**
	- 내가 사용했던 이유: '공개 라이브러리, 인터넷, AI까지 있는 시대에 모든 코드를 작성해야 하는가?'라는 의문점
	- 교수님 관점 평가: 개발 과정 단순화 및 개발 시간 단축에 유리
	- 결론: 좋은게 이미 있으면 쓰자!

- **적절한 자료구조의 선정**(실행 속도 1등)
	- 내가 사용했던 이유
		- Unix 강의에서 배운 적절한 자료 구조의 선택의 중요성
		- 1학년 때 Python의 Dictionary를 정말 유용하게 사용했던 경험
		- C++ 강의에서 배운 해시 테이블과 내부 구현 프레임 개념
	- 교수님 관점 평가
		- 발표 학생 중 실행 시간이 1초를 초과하는 프로그램도 있었다. 0.03초가 나온 내 프로그램에 비하면 33배를 초과하는 아주 큰 폭의 차이가 발생한 것. (사실 생각해보면 실행 시간이라는건 프로그램 사용에 있어서 정말 중요한 요소이다. 본인도 적절한 자료구조 선택에만 집중했었지 그 의도에 이런 점들이 있다는 것까지는 놓친 것 같음.)
		- 해시 테이블이 교재의 가장 마지막 챕터였고 바로 직전의 강의 과제가 트리 탐색 관련 과제여서 해시 테이블 자체를 놓친 학생들이 있는 것 같다.

- **생각해 볼 것**
	- 실행 환경에 대한 체크는 더욱 민감하게
	- 동작만 되면 끝이 아니라, 여기서 더 좋은 성능을 낼 수 있는지?